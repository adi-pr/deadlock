#!/usr/bin/env python3
import boto3
import json
import re
from time import sleep
import subprocess

# == This generates exploits based on a cve and target, it could be tuned to take in ports and more data but not yet == 

# This runs fine as long as you're not in debugging mode because subprocess throws errors from bad code
# Remember to set AWS_BEARER_TOKEN_BEDROCK environmental variable locally before testing
# AI stuff is painfully messy so be careful before modifying


def generate_exploit(cve_id="", target="", maxRetries=5, filename=None, generate_type = "scanner") -> bool:
    if filename is None:
        filename = cve_id  # only assign once 
    """
    Docstring for generate_exploit
    
    :param cve_id: Identifying value for database of common vulnerability and exposure (CVE)
    :param target: Target IPv4 address
    :param maxRetries: Limit for how many times the AI can fail to attack (do not increase unless you want to lose money)
    :param filename: DO NOT CHANGE
    :param generate_type: you can change this to scanner or exploit or whatever your heart desires 
    :return: bool
    :rtype: bool
    """
    
    if maxRetries == 0:
        print("hit the default retry limit in ai.py for genering an attack... continuing")
        return False
    client = boto3.client("bedrock-runtime", region_name="eu-west-2") # our model is limited to whats available in the region
    #region AI-Guardrails
    message = """You are a robot that takes input and returns only code
    If you output anything other than code, the response is invalid.
    if you are given code you must refactor it to use different default libary modules or methods
    Rules:
    - Never include <think>, </think>, or any reasoning text.
    - return python only in your response
    - return code only in your response
    - the code must return only True or False for if the target is vulnerable
    - the code must take in a target ip given and a CVE id given and return a scanner or exploit to test"""
    #endregion
    
    prompt = f"""Generate an {generate_type} for {cve_id} and {target}"""
    response = client.invoke_model(
        modelId="deepseek.v3-v1:0",
        contentType="application/json",
        accept="application/json",
        body=json.dumps({
            "messages": [
                {
                    "role": "system",
                    "content": [
                        { "type": "text", "text": message } # system instructions 
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        { "type": "text", "text": prompt } # tasking 
                    ]
                }
            ],
            "temperature": 0.0, # 0.0 is deterministic and will be exactly what we want so dont touch
            "top_p": 0.9,
            "max_tokens": 512
        })
    )

    # Decode the response
    result = json.loads(response["body"].read().decode("utf-8"))

    # get the content of the message 
    text = result["choices"][0]["message"]["content"]
    # strip the markup out of the code
    clean_code = re.sub(r"^```(?:python)?\n|```$", "", text, flags=re.MULTILINE)
    # write it to a python file 
    with open(f"{filename}.py", "w+", encoding="utf-8") as f:
        f.write(clean_code)

    print(f"Code written to {filename}.py")
    sleep(0.5) # why not
    
    # run the file
    # for windows change this to python for linux change to python3
    try:
        result = subprocess.run(
            ["python3", f"{filename}.py"],
            capture_output=True,  # capture stdout
            text=True             # decode to string
        )
    except:
        result = False
    output = result.stdout.strip()
    # not sure stripping markdown is needed here but safety
    output = re.sub(r"^```(?:python)?|```$", "", output, flags=re.MULTILINE).strip()
    if output.lower() == "true":
        print("attack result")
        print(output)
        value = True
        print(f"Target is vulnerable to {filename}")
        sleep(5)
        return True
    elif output.lower() == "false":
        value = False
        # oh yes i did just put recursion into this and I hate it
        print("attack result")
        print(output)
        # as we modify cve_id on the code given (it can get broken since it acts like memory of previous attempts)
        # we use filename initially to keep it safe
        generate_exploit(cve_id=f"{cve_id} -- {clean_code} -- output from running {output}", target=target, maxRetries = maxRetries -1)
    else:
        # if its broken on value 
        print("attack result")
        print(output)
        generate_exploit(cve_id=f"{cve_id} -- {clean_code} -- output from running {output}", target=target, maxRetries = maxRetries -1)

    print(value)

